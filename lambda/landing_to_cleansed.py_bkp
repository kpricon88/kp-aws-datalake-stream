import boto3
import json
import os
from datetime import datetime

s3 = boto3.client('s3')

def lambda_handler(event, context):
    for record in event['Records']:
        bucket = record['s3']['bucket']['name']
        key = record['s3']['object']['key']

        print(f"Processing file: s3://{bucket}/{key}")

        response = s3.get_object(Bucket=bucket, Key=key)
        raw_content = response['Body'].read().decode('utf-8')

        outer_data = json.loads(raw_content)

        try:
            raw_data = json.loads(outer_data.get("raw_data", "{}"))
        except json.JSONDecodeError:
            raw_data = {}

        cleaned_data = {
            "name": raw_data.get("name", "").strip().title(),
            "email": raw_data.get("email", "").lower(),
            "ingested_at": raw_data.get("timestamp")
        }

        print(f"Cleaned data: {cleaned_data}")

        # Save with same partition path and filename to cleansed bucket
        s3.put_object(
            Bucket=os.environ['CLEANSED_BUCKET'],
            Key=key,
            Body=json.dumps(cleaned_data),
            ContentType='application/json'
        )

    return {"status": "cleaned and written"}